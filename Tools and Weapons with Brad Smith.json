{
  "podcast_details": {
    "podcast_title": "Tools and Weapons with Brad Smith",
    "episode_title": "Kevin Scott: Putting AI into the hands of people everywhere",
    "episode_image": "https://image.simplecastcdn.com/images/ed06a4ea-5c3d-4bba-882a-7bc5eb08ceeb/7b882a07-e2a5-4f15-88bb-710fd9f778b2/3000x3000/tools-and-weapons-poster-3000x3000-a.jpg?aid=rss_feed",
    "episode_transcript": " I'm Brad Smith, and this is Tools and Weapons. On this podcast, I'm sharing conversations with leaders who are at the intersection of the promise and the peril of the digital age. We'll explore technology's role in the world as we look for new solutions for society's biggest challenges. You can look at AI as a potential way to transform really hard zero-sum problems into non-zero someones. And I think that lens is one that we ought to use more, because that's the true benefit and power of technology is helping us have more leverage, more abundance, more of everything for everyone. That's Kevin Scott, Microsoft's Chief Technology Officer, who leads the company's AI strategy. His vision to make AI a tool available to people everywhere has roots in his rural Virginia upbringing. There, he saw people with limitless creativity and grit finding genius solutions to everyday problems. Kevin explains his guiding philosophy for creating technology, forged when he was at LinkedIn, and how he applies it today to build technology in a responsible way. And he shares the goosebumps he gets when he listens to classical music and what that reveals about AI and our future. My conversation with Kevin Scott, up next on Tools and Weapons. Kevin, you are working on an extraordinary range of issues dealing with artificial intelligence. You're really at the forefront of the field. But before we turn to that, I want to ask you a little bit about what has shaped your view of the world, because I see you bring that every day to AI. Kevin, I know your view of the world starts with where you grew up, the metropolis, town of 4,000 people, Gladys, Virginia. Tell us a little bit about growing up there. Yeah, so I grew up in rural central Virginia in this town called Gladys, where I think there are more cows than there are human beings. And there are many towns like this throughout the country. I do want to interject. I grew up in Wisconsin. That was true of the entire state for me. So yes, I appreciate that. Yeah. And look, I think these are wonderful parts of the United States. My dad and my grandfather, my great grandfather were all construction workers. So neither my mom nor my dad went to college. And we didn't have a ton when I was growing up. But what I had were these hardworking, very creative people surrounding me. So my entire family had their job that they were doing where they worked with their hands. And then when they came home at night, they had these things that they would do to like more things with their hands. My dad made furniture, my grandfather restored antiques. They fiddled around with rebuilding cars. And so there was just always this flurry of activity around me. And so the two things that I really understood from very early on is that the people around me were incredibly industrious. They had this versatility and grit. They just sort of solved problems. And everybody was sort of committed to their community. So like you were just sort of acutely aware of like who everyone else was. And when someone needed a meal because they were sick or old church ladies needed firewood, like you just sort of went and solved those problems. And I think a lot of that informs how I think about our obligation to the world right now. It's not just an obligation to each other inside of Microsoft or an obligation to the tech industry that we occupy. It's sort of an obligation to everyone and just recognizing that they're ingenious, hardworking people everywhere. And if you equip them with tools, like particularly the tools of technology, they're going to go do interesting, great things in their communities and at broader scale. We are working in an industry that fundamentally was invented and built by engineers, software engineers, computer scientists, data scientists. But we're talking here about a future that needs to be built by people with a breadth of perspective that reflects many disciplines. I'll say a bigger role for the liberal arts and people who have training or interest in the liberal arts. I am sort of one of the voices of the liberal arts in the senior ranks at Microsoft. And what I have always enjoyed among many things about you is so are you. You have this extraordinary range of interests and maybe it comes from that ability to see people tinker with so many things. What do you do when you're not thinking about AI? I think that's worth people learning a little bit about. Look, I think the thing that my parents and my family gave me that maybe is the most defining thing about me, you know, other than my inventive vocabulary, which you've also been exposed to, is just this almost pathological curiosity. I want to understand everything and how everything works. And it used to drive my mother crazy because at three or four years old, I would disassemble all the appliances in the house and they'd be in various states of disarray. I tried to figure out how they worked and sometimes I could get them back together and working again and sometimes not. And so I just am constantly myself tinkering with things. My wife calls me a serial hobbyist because I will switch from one thing to another and go super deep. And so it's been photography or sometimes it's like an obsession with cooking. Like Nathan Mirval, one of the previous Microsoft CTOs, also like I think is serially obsessed with learning things. But it also, I think to your point, includes I went to a liberal arts undergraduate school and I was a computer science major and I was minoring in English. And when I got to the end of my four years, I had a computer science advisor who was like, you must go get a PhD in computer science. And I had an English advisor who was saying, you must go get a PhD in English literature. And I didn't really know which one I was going to choose because I was equally interested in both. And like it was sort of a pragmatic choice that I, you know, and this is a sad statement about society more than anything else. Like I was broke and I decided that my economic prospects were going to be better with a career in computer science, although I had no idea why. Like it was just as vague sense I had. It turns out I'm guessing it was right because I was more likely to be Kevin Scott's CTO of Microsoft, although that's a very unlikely thing in of itself than I was going to be James Patterson or Stephen King or J.K. Rowling. But a couple of months ago, you and I were at a dinner together in Washington, D.C. with about a dozen very reputable esteemed journalists. And we were talking about AI as one does when one is with journalists fielding a lot of questions. And I was sitting across this table and suddenly I heard you describing how you had been listening to classical music. Can you remember that story and share that? Yeah. One of the things that I believe is and so the context here is like people were we were having this conversation about what AI may or may not subsume about the human experience. And one of the things that I really do believe is that part of what we want from each other is connection and that the purpose of art is not just expression, but it is a desire to be connected to one another, to like the composer, to the performer, to the audience that you're sitting in, to like other people who may not be in the physical audience who are experiencing the same thing as you are, like how they're experiencing it differently and how they're experiencing it similarly. And the anecdote that I was sharing is I'm a huge classical piano fan and my very favorite composition is Chopin's G minor ballad, which is this unbelievably intense complex piece of music. And even though it's my favorite, like I have favorite performances of it, it's been performed thousands and thousands of times by thousands of different performers. And so even though they all approach the notes on the page, which are the same for all of them, and they are playing on instruments that are slightly different instrument to instrument, but like they all have 88 keys, they all are a piano is sort of a piano. What they get out of that instrument and that score is very different from performance to performance and there's some performances where I will listen to it like there's a piece of the composition where I forget exactly, I think it's bar 96, where like you have this triple fortissimo that just unleashes all of the tension that you've been building up and like there are certain performances of this where I sort of get this goosebumps, right? Every time. And I got to believe that is something about something very deeply human. Like I just can't imagine how an AI produces that because when I have it, like I'm just in such an emotional state and it is about what that performer must be thinking and feeling when he's producing this thing that is producing this reaction in me. And I think that gets to the core of something important for all of our enthusiasm about AI and for all of the potential we think it can bring. It's never going to replace what fundamentally makes us special as human beings. It can add to and augment hopefully what we do and what we achieve. And you see that through that experience. And then let me ask you about one other thing that you commented a bit about at that dinner. You still make things with your hands. Tell us what you've been making recently. I've been doing a bunch of woodworking and a bunch of funny enough leatherworking. So I make bags and a bunch of like complicated leather goods. Like handbags and the like? Yeah. So the briefcase that I carry around, like I made myself, I make my own luggage. Like it's really weird, man, when I say it out loud. No, you and I were about to walk into a meeting at the Rand Corporation earlier this year and you said, oh yeah, I made this bag that you had I think on your back or in your hand at that point. Yeah. And I do it because I really enjoy understanding how the world is put together. So like it helps me not take things for granted. So like we casually consume so much of the world. And I think we take for granted the people who have with their hands made these things that are integral parts of our daily life. And like being able to understand how things come together and to try to replicate some of these things, you know, poorly as I might myself helps me be more grateful for all of the things that I have. And it's also a good release. Like you know this very well. Your jobs are doing things that are so complex that your individual contribution to a thing is like very diffuse because you're one among a very large number of people trying to make a thing happen. And it usually takes a long time to get a thing accomplished. And so being able to make a thing like a briefcase or like a little decorative wooden box or like I made the wallet that I carry is a way to like do something by yourself. In my case, like I have one other person that I work with and over a short time horizon where you can sort of say, oh, here I did this thing. And so like it also serves that purpose where I get anxious honestly if I don't have that creative outlet, like a way to go spend a few hours, like do something with my hands and then see what it is that I made because that's not the way my job as CTO works. One of the things that I think is interesting about life is we all look at the world through our own eyes by definition and they reflect our own unique experience. And here in 2023, one question that people are sometimes asking is how did Microsoft and OpenAI come together? And a big part of the answer is through you, through Kevin Scott. But what I love, I've heard our mutual boss Satya Nadella, Microsoft CEO describe it, is Sam Altman asked me if we would provide more support. So I asked Kevin Scott if he'd go over and spend some time and see if there was a future. You were not excited about spending that day there when you first got that, I'll just say request in quotes from Satya. What were you thinking when you embarked on that day to sit down and understand what OpenAI was working on? Yeah, I think the thing that people, even here inside of Microsoft, don't remember is we had a partnership with OpenAI prior to that conversation that Satya and Sam had. So they had gotten some credits from Microsoft to do some of their first training runs on top of Azure. And the thing that I was concerned about at the beginning is like, okay, are we just going to be a source of funding for compute versus having some deeper partnership? And I was a little bit skeptical even that we were on a path to making super fast progress. Like I've been working on machine learning things for a whole bunch of years. You know, like my first job in industry was doing some machine learning work and advertising and search systems. And I just didn't really fully appreciate that we had gotten ourselves onto a path where things were going to sort of scale up with the amount of data and compute that we could feed to AI systems in ways that were going to make the AI models much, much more compelling. And so when I had that first meeting, I wasn't the only one who was skeptical. And you can see the skepticism even persisting today. That period of time between when GBT-4 existed and when the world knew it existed, there were all sorts of people making all sorts of claims about this will never work or this is impossible where we inside of the company and at OpenAI could sort of see that the things people were using as evidence of impossibility or solve problems now. And so that conversation that I had with Sam and his team at OpenAI was eye opening in a whole bunch of ways about how they had really solved some very interesting problems. Sam has been talking about quite eloquently lately about not just being able to scale up the capability of AI with more compute and data, but having that scale up be predictable. And as soon as I had seen those two things, I knew that we were going to be able to do something very interesting with OpenAI. In a way that perhaps most people wouldn't necessarily know about or appreciate, do you think it helped you see what OpenAI could build having grown up surrounded by people who were constantly solving the day's problems by building all sorts of solutions? Yeah, I think so. I mean, this is maybe the most important thing about the OpenAI and Microsoft partnership is we're sort of both aligned on this notion that we're building AI to put into the hands of other people so they can create with it. And so this idea of building very powerful AI and like the only people who get to decide how it functions, what it gets used for, like how it's steered is a handful of people in big tech companies is not nearly as interesting to me as this idea that we're building a platform for other people to create on top of. Because like I just know, and I'm sure this is your experience as well, like you grow up in one of these communities that's very different from Silicon Valley or the Pacific Northwest or New York City or Beijing or like pick your place where a lot of technical innovation is happening. And yeah, people have different problems. They think about the world differently. They have different urgencies around things that they care about. And you want to equip everyone with really amazing tools so that they can do their best work and so they can solve problems that you couldn't even imagine. And like to me, that's the exciting thing, just watching what a creative person does who has a different point of view from me make something amazing that I find surprising and would never have built myself. And I of course appreciate personally because I've worked with you for a number of years that this is not something new for you. It's a real passion, a passion that has not only led to what you're doing at Microsoft, but you've literally written a book about this, Reprogramming the American Dream. And it's fundamentally focused on as the subtitle is, Making AI Serve Us All. And your book didn't come out at the best moment in time. It arrived about the same time as the pandemic. It's hard to do a book tour during a pandemic. But you really focus in the book about how to use AI as a tool so that we can solve the world's problems without thinking about everything as sort of a zero sum game to calculate scarce resources. It's really the story that you just shared here. But can you share a little bit with us about that broader perspective that you have been nurturing really for several years? I think the history of human innovation is trying to use technology and tools to turn zero sum problems into non zero sum ones. And for those people who have never heard of this, like there's this idea in game theory, which is a branch of mathematics that describes certain types of games where a zero sum game is one where there's a winner and a loser and zero sum problems in general. Like even if they're not binary games with one winner and one loser, they typically have a finite number of resources and the outcome of the game. Like you have to apportion those finite resources to the players of the game. And I think we can sort of see in our lives the most contentious things that we face as human beings are typically zero sum. Like they're ones where we've got some restricted pool of resources and we have to figure out how to allocate them to a bunch of people who may all be equally deserving of a share of those resources or where. Like I sort of think about this in terms of college admissions. Like I've got a 14 year old right now who's sort of obsessed with where it is she's going to go to school. And I just look at how many really bright kids don't get into the schools that they want because college admissions are sort of a zero sum thing. Like education tends to be a zero sum thing because we have more educational need than we have capacity to teach. Like medicine can be a zero sum game because like we have more need for medicines and therapies and healthcare resources than we have capacity. And so the story of humanity, and this is a thing that I was super influenced by as an undergraduate student by an author named Robert Wright who wrote a book called Non-Zero is whenever we are able to take a piece of technology and turn one of these zero sum things into a non-zero sum where we take scarcity and constraints and create abundance and release the constraints, we are able to do really amazing things. And I think that if you look at the future that we're facing, even some of the things that I just mentioned like healthcare and education, like you can look at AI as a potential way to transform really hard zero sum problems into non-zero sum ones. And I think that lens is one that we ought to use more because that's the true benefit and power of technology is helping us have more leverage, more abundance, more of everything for everyone. And one of the things I find interesting about what you just said is I think right now around the world there are people, including people I'm sure who are listening to this who are going, uh-huh, that sounds good. But I feel like I've heard that before. I feel like I've heard you tech guys, usually it's guys, get too excited, all wrapped up in yourselves and you create more problems than you actually solve. And then they say that's what happened with social media. Yeah, without trying to make a statement about any other company, I want to ask you this. You're not just the CTO of Microsoft. You came to Microsoft having been the chief technology officer of LinkedIn. And I would argue that across the social network landscape, LinkedIn has always stood out. It's why we wanted to acquire the company as doing what you just said, creating a social network that created more opportunity and actually created benefits in very important ways. That in part was your vision. How did you bring that vision into reality at LinkedIn? Well, like it wasn't my vision originally, like it was Reid Hoffman's vision. And then a thing that a whole bunch of people opted into, and I think this is like a really interesting thing from a career perspective, like mission matters. It matters a lot. Like LinkedIn's mission was connect the world's professionals to help them be more productive and successful. And we live that mission every day. So like we ask ourselves and the things that we were doing, whether it was building a piece of infrastructure or like building a new feature or a new product, we ask ourselves whether or not that thing was going to be true to that mission. Was it going to help someone be more productive? Was it going to help someone be more successful? Was it going to help connect people around the world? I think just really building a culture at a company where you can be mission oriented and you're always called back to that is really interesting. And it results in you having a team of people who are very passionate about a shared vision that they have for what they're putting their labor towards. And it like helps you deal with some hard questions because there are many things that can pull you off mission, like many, many things that are seem like good ideas, that seem attractive, that are where an incentive exists to like pull you in a direction. And if you have the culture inside of a company to always question whether or not those sort of pulls that you're having that may bring you off mission are really orthogonal versus things that make the focus of the mission stronger. Like I think you end up doing reasonably good things over time. It's one of the things I'm excited about at Microsoft and one of the reasons why I have always admired Satya and like the senior leadership team. And I wanted to be the CTO of the company when Satya offered to let me do that, which just seemed like a crazy thing at the time. The mission of Microsoft like as a platform company is empowering every individual and organization on the planet to achieve more. I think it's one of the reasons why the LinkedIn acquisition has actually been successful is like that Microsoft mission I just articulated is so close to the LinkedIn mission. And I'll grant you, as Reid Hoffman's vision, I'll say you played an indispensable role in operationalizing it and turning it into reality and you are doing it again here at Microsoft around AI and this whole focus that we have about building what we call responsible AI, ethical AI. You and I co-chair the Responsible AI Council. What are the challenges that you're confronting anew? These challenges in doing for Microsoft and AI what you did at LinkedIn on a smaller scale. I believe I said this in my book. We as technologists don't get to do whatever it is we want. Like we have to be serving some interest of society. Like society has to trust that we are acting responsibly and in their interest over time. Otherwise we lose the permission that we have to do what we want. And to believe that we don't need the permission of the world to do what we're doing is like a very weird and naive and incorrect assumption I think that people have. And so part of doing responsible AI I think is sort of doing what is necessary to safely and responsibly take a technology that has in my opinion like overwhelmingly more benefits than it has risk and harms. But it is like confronting the possibility of those risks and harms head on not being Pollyanna or dismissive of them and trying to figure out how you not just build the infrastructure that helps you deploy things in a safe way but you build a culture where like by the time things get to the safeguarding mechanisms that you're building like either processes or technology that the teams who built things have already considered most of what your safeguards are trying to enforce on those products that they are deploying. So in that sense like I think the responsible AI program that you and I are running is like partially about like building safeguards but it's also partially about building culture and like maybe that culture is the more important part of what it's doing. It was striking earlier this year because there were some skeptics and especially in the journalistic community which has the job of being skeptical and I think that serves us all when they are but they looked at Microsoft, they looked at Google and they said you all are going so fast you're clearly throwing caution to the wind. When you think about that type of criticism or concern how do you think we're doing in building the culture we need to ensure that AI is developed in a responsible way? So in my opinion and like it's maybe not for me to judge because obviously like I have a whole bunch of biases. Ultimately if society will have to judge what we're doing but I think we're doing a very good job like we're trying to listen very carefully to a very broad range of stakeholders whether it's the work that you and I have been doing with the governments of a bunch of very important countries who are rightfully concerned about what the impacts of this technology both positive and negative are going to be on their citizens and it is academics, it's journalists but it's also the consumers of the products and the people who are going to build on top of the platform. So like one of the things that we chose to do is we actually want to deploy the technology. It's very hard to figure out what it is that a platform should do or what it is that a product needs to do to benefit users unless you actually launch the product and get the feedback and sort of see how the systems behave in the real world. And so part of our job with responsible AI at Microsoft is like just being very clear-eyed about where the red lines are like things that we will never do because it is just blindingly clear and everybody with a functioning brain can agree that X, Y or Z is dangerous and we must prevent it from happening. And then there are like all of these things that are sort of fuzzy where the only way that we're going to figure out where we want to draw the line either for individuals or organizations or society is to have individuals, organizations and society exposed to the technology enough so that they can form a really good opinion about what it is we should do. Well I know we're out of time but I'd love to sit down and take stock of this conversation and say a year or two and we'll compare where we are then with where we are now. But what I would say is this, I actually think that all of these disparate things that you've described during this conversation actually come together. And as we look at where this extraordinary new technology is going, it's actually a really good thing. I at least sleep better at night knowing that the chief technology officer for Microsoft actually spends some time creating his own luggage, appreciating classical piano, has this breadth of interests, developed a responsible social network at LinkedIn and grew up in Gladys, Virginia. So Kevin, thanks for the opportunity I have to work with you. Thank you for sharing some of this. Actually the future of technology depends in some ways and in many different places on people who can always remember what actually is most important about keeping us grounded and making us human. You embody all of that. Thank you so much. You're too kind. Thanks for having me on today. See you at our next meeting. Yeah, awesome. Thank you. You've been listening to Tools and Weapons with me, Brad Smith. If you enjoyed today's show, please follow us wherever you like to listen. Our executive producers are Carol Ann Brown and Aaron Tese. This episode of Tools and Weapons was produced by Karina Hernandez and Jordan Rothlein. This podcast is edited and mixed by Jenny Cattaldo with production support by Sam Kirkpatrick at Run Studios. Original music by AngularWave Research. Tools and Weapons is a production of Microsoft, made in partnership with Listen."
  },
  "podcast_summary": "In this podcast episode, Brad Smith interviews Kevin Scott, Microsoft's Chief Technology Officer, about his vision to make AI a tool available to people everywhere. Kevin explains how his rural upbringing in Gladys, Virginia shaped his view of the world, emphasizing the creativity and problem-solving abilities of people in small towns. He believes that by equipping individuals with tools like AI, they can solve problems and create positive change in their communities. Kevin also discusses the importance of the liberal arts in technology, his curiosity-driven nature, and his passion for woodworking and leatherworking. He shares his perspective on responsible AI and the challenges of developing AI in a way that benefits society. Overall, Kevin believes that technology, when used responsibly and in alignment with society's interests, can create more abundance and opportunities for everyone.",
  "podcast_guest": "Kevin Scott",
  "podcast_highlights": "People are interested in integrating AI into their lives for a variety of reasons. AI technology has the potential to transform zero-sum problems into non-zero-sum ones, meaning that it can help create more abundance and solutions for everyone. AI can provide leverage and efficiency, making tasks easier and improving productivity. It can also help solve complex problems and provide new insights by processing and analyzing massive amounts of data. Additionally, AI has the potential to enhance our daily lives by providing personalized recommendations, improving healthcare outcomes, and optimizing various systems and processes. Overall, people see AI as a tool that can help us achieve more, find innovative solutions, and improve the quality of our lives."
}
